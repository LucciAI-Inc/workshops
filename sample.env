## FOR OPENAI MODELS
OPENAI_API_KEY=xxxxxxxxxxxxxxxxx


## FOR LUCCI MODELS
LUCCI_API_KEY=xxxxxxxxxxxxxxx

## FOR CUSTOM MODELS - ENTER AN API ENDPOINT
API_ENDPOINT_TGI="https://t89x61u0xbl2f4-8080.proxy.runpod.net" #for runpod TGI or llama.cpp, should be in the form of: "https://<POD-ID>-8080.proxy.runpod.net"
API_ENDPOINT_VLLM="https://xxx.xxx.xx" #for runpod vLLM, should be in the form of: "https://<POD-ID>-8000.proxy.runpod.net"

MODEL='LucciAI/openchat-3.5-0106-function-calling'
POD_ID='xxxxxxxxxxxxxx'
FOLDER_PATH='xxxxxxxxxxxxxx'